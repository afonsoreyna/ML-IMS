{\rtf1\ansi\ansicpg1252\cocoartf2706
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 DecisionTreeClassifier(criterion='entropy', max_depth=6, max_features=8,\
                       splitter='random')\
              precision    recall  f1-score   support\
\
           0       0.87      0.87      0.87       389\
           1       0.88      0.87      0.87       411\
\
    accuracy                           0.87       800\
   macro avg       0.87      0.87      0.87       800\
weighted avg       0.87      0.87      0.87       800\
\
LogisticRegression(C=50, penalty='l1', solver='saga')\
              precision    recall  f1-score   support\
\
           0       0.85      0.84      0.84       389\
           1       0.85      0.85      0.85       411\
\
    accuracy                           0.85       800\
   macro avg       0.85      0.85      0.85       800\
weighted avg       0.85      0.85      0.85       800\
\
MLPClassifier(hidden_layer_sizes=(10, 30, 10))\
              precision    recall  f1-score   support\
\
           0       0.90      0.90      0.90       389\
           1       0.91      0.90      0.91       411\
\
    accuracy                           0.90       800\
   macro avg       0.90      0.90      0.90       800\
weighted avg       0.90      0.90      0.90       800\
\
GaussianNB(var_smoothing=0.01)\
              precision    recall  f1-score   support\
\
           0       0.82      0.85      0.84       389\
           1       0.85      0.82      0.84       411\
\
    accuracy                           0.84       800\
   macro avg       0.84      0.84      0.84       800\
weighted avg       0.84      0.84      0.84       800\
\
GradientBoostingClassifier(max_depth=5, n_estimators=500)\
              precision    recall  f1-score   support\
\
           0       0.97      0.98      0.98       389\
           1       0.98      0.97      0.98       411\
\
    accuracy                           0.98       800\
   macro avg       0.98      0.98      0.98       800\
weighted avg       0.98      0.98      0.98       800\
\
RandomForestClassifier(bootstrap=False, max_depth=110, max_features='sqrt',\
                       n_estimators=200)\
              precision    recall  f1-score   support\
\
           0       0.98      0.98      0.98       389\
           1       0.98      0.98      0.98       411\
\
    accuracy                           0.98       800\
   macro avg       0.98      0.98      0.98       800\
weighted avg       0.98      0.98      0.98       800}